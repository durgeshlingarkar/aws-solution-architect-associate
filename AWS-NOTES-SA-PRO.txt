SA-PRO

Domain 8 - Cloud Migration & Hybrid

- VCenter has a pluggin that enables you to migrate VMware VMs to Amazon EC2 and manage AWS resources from within VCenter.
- Usecases for this are 
	- Migrate VMWare VMs to Amazon EC2
	- Reach new geographies from VCenter
	- Self service AWS portal within VCenter
	- Leverage VCenter experience while getting started with AWS.
	
- Use Storage gateway to migrate your existing VMs to AWS
- To ensure snapshots are consistent, power down your VM and then take the snapshot in offline mode.

- Data Pipeline
	- Data pipeline is a webservice that helps you to process or move data between different AWS compute and storage services.
	- Can be ingerated with on premises environment
	- Can be scheduled
	- Data pipeline will provision and terminate resources as and when required. 
	- A lot of data pipeline's functionality is replaced by LAMBDA
	- A data pipeline consists of 
		- Datanode : where you are gonna store the data.
		- Activity : Any activity to process/move data
		- Precondition : Conditions or filter to trigger activity
		- Schedule : Schedule for activity to run

VPC & CIDR 

- When you create a subnet, you create a CIDR block for the subnet. The allowed block size is between /28 netmask and /16 netmask. 
- If you create more than one subnet in a VPC, the CIDR blocks of the subnets must not overlap.
- 5 IP addressed are always reserved per CIDR block. Following are the reseved IP addresses for CIDR block 10.0.0.0/24
	- 10.0.0.0 - Network address
	- 10.0.0.1 - Reserved by AWS for VPC router.
	- 10.0.0.2 - Reserved by AWS for mapping to Amazon provided DNS.
	- 10.0.0.3 - Reserved by AWS for future use.
	- 10.0.0.255 - Network broadcast address. AWS does not support broadcast in a VPC, therefore they reserve this address.
	
	

VPN to Direct Connect Migrations. 

- Most customers will have site-to-site VPN tunnel from their location to AWS. But as traffic gets heavier, they will opt to use direct connect.
- Once direct connect is installed, you should configure it so that your VPN connection & your direct connect connection are within the same BGP community. You then configure BGP, so that your VPN connection has a higher cost than the Direct connect connection. 


Networking Components

Elastic Network Interfaces

- An elastic network interface (referred to as a network interface in this documentation) is a virtual network interface that can include the following attributes:

	- a primary private IPv4 address
	- one or more secondary private IPv4 addresses
	- one Elastic IP address per private IPv4 address
	- One public IPv4 address, which can be auto-assigned to the network interface for eth0 when you launch an instance
	- one or more IPv6 addresses
	- one or more security groups
	- a MAC address
	- a source/destination check flag
	- a description
	
- You can create a network interface, attach it to an instance, detach it from an instance, and attach it to another instance.
- Each instance in your VPC has a default network interface (the primary network interface) that is assigned a private IPv4 address from the IPv4 address range of your VPC. You cannot detach a primary network interface from an instance.
- You can create and attach an additional network interface to any instance in your VPC. The number of network interfaces you can attach varies by instance type.


Domain 7 : Scalability & Elasticity

Cloudfront 

- is used to deliver entire website, including dynamic, static, streaming and interactive content using a global network of edge locations. 
- Requests for contents are automaticallu routed to the nearest edge location, so content is delivered with best possible performance. Cloudfront is optimized to work with with other webservices like S3, EC2, ELB & Route53. 
- 2 types of distributions 
	- Web Distribution - Streams HTTP protocol
	- RTMP - Streams RTMP protocol
- Geo restriction also called as Geo blocking lets you choose the countries where you want to restrict access to your content. 
- Whitelists or Blacklists particular countries using either API or console. 
- Viewers from blacklisted countries will see HTTP 403 error. You can also create custom error pages. 
- Cloudfront supports GET, HEAD, POST, PUT, PATCH, DELETE and OPTIONS.
- It does not cache responses to POST, PUT, PATCH, DELETE requests, these requests are proxied back to origin server. 
- You can use both HTTP & HTTPS with cloudfront. 
- With SSL, you can use the default cloudfront URL or ur custom URL with your own certificate.
- For custom URL with your own certificates there are 2 ways 
	- Dedicated IP custom SSL : Allocated dedicated IP addresses to serve your SSL content to each cloudfront edge location. Very expensive. $600 USD per certificate per month. However, will support older browsers. 
	- SNI custom SSL : Relies on SNI (Server Name Indication) extenstion of transport layer security protocol, which allows multiple domains to serve SSL traffic over  the same IP address by including the hostname, viewers are trying to connect to. Older browsers won't support it. 
- CNAME : You can have 100 CNAMES aliases to each distribution. Cloudfront supports wildcard CNAMES. 
- Invalidations Requests : There are multuiple options for removing a file from the edge locations. You can simple delete the file from your origin and as content in the edge locations reaches the expiration period defined in the each object's HTTP header, it will be removed. If there is offensive or potentially harmful material that needs to be removed before the expiration then you can use Invalidation API to remove the object from all cloudfront edge locations. 
- Zone APEX Support : Using Route53, AWS's authoritative DNS service, you can configure an 'Alias' record that lets you map the apex or root (example.com) of your DNS name to your AMAZON Cloudfront distribution. Eg http://example.com --> http://d12878rt.cloudfront.net . Route53 will then respond to each request with the right IP addresses for your Cloudfront distribution. Route53 doesn't charge for queries to Alias records that are mapped to a cloudfront distribution. 
- Dynamic content support : Cloudfront supports delivery of dynamic content that is customized or personalized using HTTP cookies. To use this feature, you specify whether you want cloudfront to forward some or all cookies to ur custom origin server. cloudfront that considers the forwarded cookie values when identifying a unique object in it's cache. This way you end users get both the benefit of content that is personalized just for them with a cookie and the performance benefits of cloudfront. You can optionally choose to log the cookie values in cloudfront access logs. 
- Cost Saving with Amazon CloudFront
	-Amazon CloudFront has no minimum commitments and charges you only for what you use. 
	- Compared to self-hosting, Amazon CloudFront spares you from the expense and complexity of operating a network of cache servers in multiple sites across the internet and eliminates the need to over-provision capacity in order to serve potential spikes in traffic.
	-Amazon CloudFront also uses techniques such as collapsing simultaneous viewer requests at an edge location for the same file into a single request to your origin server. This reduces the load on your origin servers reducing the need to scale your origin infrastructure, which can bring you further cost savings.
	- if you are using an AWS origin (e.g., Amazon S3, Amazon EC2, etc.), effective December 1, 2014, we are no longer charging for AWS data transfer out to Amazon CloudFront. This applies to data transfer from all AWS regions to all global CloudFront edge locations.
- CloudFront supports origin redundancy
	- For every origin that you add to a CloudFront distribution, you can assign a backup origin that can used to automatically serve your traffic if the primary origin is unavailable
	- You can choose a combination of HTTP 4xx/5xx status codes that, when returned from the primary origin, trigger the failover to the backup origin. The two origins can be any combination of AWS and non-AWS origins.
- CloudFront Regional Edge Cache
	- CloudFront delivers your content through a worldwide network of data centers called edge locations. The regional edge caches are located between your origin web server and the global edge locations that serve content directly to your viewers. This helps improve performance for your viewers while lowering the operational burden and cost of scaling your origin resources.
- Amazon CloudFront establishes WebSocket connections only when the client includes the 'Upgrade: websocket' header and the server responds with the HTTP status code 101 confirming that it can switch to the WebSocket protocol.
- Field-Level Encryption is a feature of CloudFront that allows you to securely upload user-submitted data such as credit card numbers to your origin servers. Using this functionality, you can further encrypt sensitive data in an HTTPS form using field-specific encryption keys (which you supply) before a PUT/ POST request is forwarded to your origin. 
- Usecase for field level encryption 
	- Many web applications collect sensitive data such as credit card numbers from users that is then processed by application services running on the origin infrastructure. All these web applications use SSL/TLS encryption between the end user and CloudFront, and between CloudFront and your origin. Now, your origin could have multiple micro-services that perform critical operations based on user input. However, typically sensitive information only needs to be used by a small subset of these micro-services, which means most components have direct access to these data for no reason. A simple programming mistake, such as logging the wrong variable could lead to a customer’s credit card number being written to a file.With field-level encryption, CloudFront’s edge locations can encrypt the credit card data. From that point on, only applications that have the private keys can decrypt the sensitive fields. So the order fulfillment service can only view encrypted credit card numbers, but the payment services can decrypt credit card data. This ensures a higher level of security since even if one of the application services leaks cipher text, the data remains cryptographically protected.
- Amazon CloudFront has an optional private content feature. When this option is enabled, Amazon CloudFront will only deliver files when you say it is okay to do so by securely signing your requests. 


Elasticache 
	- Memchached
	- Use Memcached if 
		- You want the simplest model possible. 
		- You need to run large nodes with multiple cores or threads. 
		- You need the ability to scale out, adding and removing nodes as demand on your system increases or decreases. 
		- You want to shard your data across multiple nodes. 
		- You need to cache objects, such as a database.
		
	- Redis
	- Use Redis if
		- You want complex data types such as strings, hashes, lists and sets. 
		- You want to sort or rank in-memory data-sets. 
		- You want persistence of your key store. 
		- You want to replicate your data from the primary to one or more read replicas for availability. 
		- You need automatic failover if any one of your primary nodes fail.
		- You want publish and subscribe (pub/sub) capabilities - the client being informed of events on the server.
		- You want backup and restore capabilities.
		
Kinesis Streams
	- Kinesis stream enables you to build custom applications that process or analyze streaming data for specialized needs.You can continously add various types of data, such as clickstreams, application logs, and social media to an Amazon Kinesis Stream from hundreds of thousands of sources. Within seconds, the data will be available for your Amazon Kinesis applications to read and process from the stream.
	- Key concepts
		- Data producers can produce data using
			- Amazon Kinesis Streams API
				- PutRecord (Single data record)
				- PutRecords (Multiple data record)
			- Amazon Kinesis Producer Library (KPL)
				- On GitHub. By using KPL, customers do not need to develope the same logic every time they create a new application for data ingestion.
			- Amazon Kinesis Agent
				- Prebuilt java application you can install on your linux devices. 
		- Shards
			- A shard is simply the unit of measurement of data when reffering to Kinesis. One shard provides a capacity of 1MB/Sec data input and 2MB/Sec data output. One shard can support upto 1000 PUT records per second. You will specify the number of shards needed when you create a stream. For example, you can create a stream with 2 shards. This stream has a throughput of 2MB/sec data input and 4MB/sec data output, and allows upto 2000 PUT records per second. You can dynamically add or remove. shards from your stream as your data throughput changes via resharding.
		- Records
			- Sequence Number
				- Each data record has a unique sequence number. Think of it as a unique key. The sequence number is assigned by streams after you write to the stream with client.PutRecord or client.PutRecords .You cant use sequence number to logically seperate data in terms of what shards they have come from - you can only do this using partition keys.
			- Partition Key
				- Kinesis streams can consist of many different shards. You can group the data by shard by using a partition key. Essentinally, the partion key tells you which shard the data belongs to. A partition key is specified by the applications putting the data into the stream. 
			- Data Itself(Blob)
				- Data blobs are the data your producer adds to the stream. The maximum size of a data blob (the data payload after base-64 decoding) is 1MB.
		- Data Consumers (Kinesis Streams Applications)
		- Data is stored for 24 hours by defaut within streams. This can be increased upto 7 days.
		- Use S3, Redshift etc to store processed data for longer term. Kinesis streams is not persistent storage.
		

	
